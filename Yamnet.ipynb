{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "#Helper function from the NN\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "#160ms and 3kz\n",
    "\n",
    "def load_wav_for_map(filename, label,indice):\n",
    "  return load_wav_16k_mono(filename), label,indices\n",
    "\n",
    "#tkt\n",
    "def create_data_from_path(path, length,label):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(np.arange(length))\n",
    "    return dataset.map(lambda index: (path + str(index), label))\n",
    "\n",
    "def extract_embedding(wav_data, label,indice):\n",
    "  ''' run YAMNet to extract embedding from the wav data '''\n",
    "  scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
    "  num_embeddings = tf.shape(embeddings)[0]\n",
    "  return (embeddings,\n",
    "            tf.repeat(label, num_embeddings),\n",
    "            tf.repeat(indice, num_embeddings))\n",
    "\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n",
    "\n",
    "nb_of_samples_per_class = 65\n",
    "path_to_deformed = \"./samples_A_DEFORMED1_C0/sample_A_DEFORMED1_C0\"\n",
    "path_to_RX = \"./samples_A_RX1_C0/sample_A_RX1_C0\"\n",
    "\n",
    "\n",
    "vfuncRx = np.vectorize(lambda index: (path_to_RX + str(index)+ \".wav\"))\n",
    "vfuncDeformed = np.vectorize(lambda index: (path_to_deformed + str(index)+ \".wav\"))\n",
    "indices = np.arange(nb_of_samples_per_class)\n",
    "\n",
    "filenamesRX = vfuncRx(indices)\n",
    "filenames_deformed = vfuncRx(indices)\n",
    "\n",
    "#we assign label 0 to RX and 1 to deformed\n",
    "labelsRX = np.zeros(nb_of_samples_per_class) \n",
    "labelsDeformed = np.ones(nb_of_samples_per_class)\n",
    "\n",
    "filenames = np.concatenate((filenamesRX, filenames_deformed))\n",
    "labels = np.concatenate((labelsRX, labelsDeformed))\n",
    "#random values added in order split the data later\n",
    "rand = np.random.rand(len(filenames)) * 10\n",
    "dataRX = tf.data.Dataset.from_tensor_slices((filenames, labels,rand))\n",
    "\n",
    "dataRX = dataRX.map(load_wav_for_map)\n",
    "\n",
    "dataRX = dataRX.map(extract_embedding).unbatch()\n",
    "\n",
    "#Split the data\n",
    "cached_data = dataRX.cache()\n",
    "dataRX.cache()\n",
    "\n",
    "train_ds = cached_data.filter(lambda embedding, label, rand: rand < 2)\n",
    "other = cached_data.filter(lambda embedding, label, rand: rand >=7)\n",
    "test_ds = other.filter(lambda embedding, label, rand: rand <= 8)\n",
    "val_ds = other.filter(lambda embedding, label, rand: rand > 8)\n",
    "\n",
    "remove_indice_column = lambda embedding, label, indice: (embedding, label)\n",
    "\n",
    "train_ds = train_ds.map(remove_indice_column)\n",
    "val_ds = val_ds.map(remove_indice_column)\n",
    "test_ds = test_ds.map(remove_indice_column)\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 525,826\n",
      "Trainable params: 525,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1024), dtype=tf.float32,\n",
    "                          name='input_embedding'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "], name='my_model')\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                            patience=3,\n",
    "                                            restore_best_weights=True)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Input element must have the same batch size in each component. Component 0 had size 63 but component 2 had size, 4095.\n\t [[node IteratorGetNext\n (defined at /home/fermeli/.local/lib/python3.8/site-packages/keras/engine/training.py:866)\n]] [Op:__inference_train_function_16391]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node IteratorGetNext:\nIn[0] iterator (defined at /home/fermeli/.local/lib/python3.8/site-packages/keras/engine/training.py:1216)\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 583, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 1248, in inner\n>>>     self.run()\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 1162, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 326, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 326, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 326, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2857, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3062, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-4-e33d09a54140>\", line 1, in <module>\n>>>     history = my_model.fit(train_ds,\n>>> \n>>>   File \"/home/fermeli/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/fermeli/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/home/fermeli/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/home/fermeli/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 866, in step_function\n>>>     data = next(iterator)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-14f99faf6773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = my_model.fit(train_ds,\n\u001b[0m\u001b[1;32m      2\u001b[0m                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                        \u001b[0;31m#validation_data=val_ds,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                        callbacks=callback)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Input element must have the same batch size in each component. Component 0 had size 63 but component 2 had size, 4095.\n\t [[node IteratorGetNext\n (defined at /home/fermeli/.local/lib/python3.8/site-packages/keras/engine/training.py:866)\n]] [Op:__inference_train_function_16391]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node IteratorGetNext:\nIn[0] iterator (defined at /home/fermeli/.local/lib/python3.8/site-packages/keras/engine/training.py:1216)\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 583, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 1248, in inner\n>>>     self.run()\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 1162, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 326, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 326, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 326, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2857, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3062, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-4-e33d09a54140>\", line 1, in <module>\n>>>     history = my_model.fit(train_ds,\n>>> \n>>>   File \"/home/fermeli/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/fermeli/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/home/fermeli/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/home/fermeli/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 866, in step_function\n>>>     data = next(iterator)\n>>> "
     ]
    }
   ],
   "source": [
    "history = my_model.fit(train_ds,\n",
    "                       epochs=2,\n",
    "                       #validation_data=val_ds,\n",
    "                       callbacks=callback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
